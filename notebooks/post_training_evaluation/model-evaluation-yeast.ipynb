{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gseapy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as pyg\n",
    "# enable multiple outputs in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pyg.seed_everything(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:31:16.567297Z",
     "start_time": "2024-05-27T18:31:16.547259Z"
    }
   },
   "id": "8a5ae1a96c94632d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%qtconsole"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T17:55:46.758125Z",
     "start_time": "2024-05-27T17:55:46.749924Z"
    }
   },
   "id": "8c06969b92268d01",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/Documents/Grape-Pi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgu3/anaconda3/envs/python311/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'/Users/cgu3/Documents/Grape-Pi'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /Users/cgu3/Documents/Grape-Pi\n",
    "%pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T17:55:48.082931Z",
     "start_time": "2024-05-27T17:55:48.079513Z"
    }
   },
   "id": "46536a5b544c4ffe",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:02.411844Z",
     "start_time": "2024-05-27T18:31:18.649962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--cfg'], dest='cfg_file', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, required=True, help='The configuration file path.', metavar=None)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--repeat'], dest='repeat', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='The number of repeated jobs.', metavar=None)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "_StoreTrueAction(option_strings=['--mark_done'], dest='mark_done', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Mark yaml as done after a job has finished.', metavar=None)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=[], dest='opts', nargs='...', const=None, default=None, type=None, choices=None, required=True, help='See graphgym/config.py for remaining options.', metavar=None)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[0.0789],\n         [0.0690],\n         [0.0809],\n         ...,\n         [0.0622],\n         [0.0622],\n         [0.0622]], grad_fn=<AddmmBackward0>),\n tensor([1, 0, 0,  ..., 0, 1, 0], dtype=torch.int32))"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphsageGraphGymModule(\n",
      "  (model): GNN(\n",
      "    (encoder): FeatureEncoder()\n",
      "    (pre_mp): GeneralMultiLayer(\n",
      "      (Layer_0): GeneralLayer(\n",
      "        (layer): Linear(\n",
      "          (model): Linear(1, 10, bias=True)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mp): GNNStackStage(\n",
      "      (layer0): GeneralLayer(\n",
      "        (layer): SAGEConv(\n",
      "          (model): SAGEConv(10, 10, aggr=mean)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_mp): ExampleNodeHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): Linear(\n",
      "            (model): Linear(10, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cpu\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: data/yeast-LCQ\n",
      "  edge_dim: 128\n",
      "  edge_encoder: False\n",
      "  edge_encoder_bn: True\n",
      "  edge_encoder_name: Bond\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: False\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG\n",
      "  label_column: None\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: protein\n",
      "  node_encoder: False\n",
      "  node_encoder_bn: True\n",
      "  node_encoder_name: Atom\n",
      "  numeric_columns: ['protein_probability']\n",
      "  rebuild: True\n",
      "  remove_feature: False\n",
      "  remove_unlabeled_data: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  split: [1, 0, 0]\n",
      "  split_mode: random\n",
      "  task: node\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: None\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: add\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 10\n",
      "  dropout: 0.0\n",
      "  head: protein\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: sageconv\n",
      "  layers_mp: 1\n",
      "  layers_post_mp: 1\n",
      "  layers_pre_mp: 1\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: skipsum\n",
      "gpu_mem: False\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: auc\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: add\n",
      "  loss_fun: binary_cross_entropy_with_weight\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: gnn\n",
      "num_threads: 6\n",
      "num_workers: 8\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 300\n",
      "  momentum: 0.9\n",
      "  optimizer: adam\n",
      "  scheduler: none\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 0.0005\n",
      "out_dir: results/yeast-graphsage\n",
      "params: 241\n",
      "print: both\n",
      "round: 4\n",
      "run_dir: results/yeast-graphsage\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 1\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: False\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 128\n",
      "  ckpt_clean: False\n",
      "  ckpt_period: 10\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: 0\n",
      "  eval_period: 10\n",
      "  grape_pi: graphsage\n",
      "  iter_per_epoch: 32\n",
      "  loss_pos_weight: 1.2393579902302863\n",
      "  neighbor_sizes: [20, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: neighbor\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "Num parameters: 241\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import custom_graphgym # noqa, register custom modules\n",
    "import torch\n",
    "from torch_geometric import seed_everything\n",
    "import argparse\n",
    "from torch_geometric.graphgym.config import (\n",
    "    cfg,\n",
    "    dump_cfg,\n",
    "    load_cfg,\n",
    "    set_out_dir,\n",
    "    set_run_dir,\n",
    ")\n",
    "from torch_geometric.graphgym.model_builder import create_model\n",
    "from torch_geometric.graphgym.register import train_dict\n",
    "from torch_geometric.graphgym.train import GraphGymDataModule, train\n",
    "from torch_geometric.graphgym.utils.agg_runs import agg_runs\n",
    "from torch_geometric.graphgym.utils.comp_budget import params_count\n",
    "from torch_geometric.graphgym.utils.device import auto_select_device\n",
    "\n",
    "from graphgym import logger\n",
    "import shlex\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GraphGym')\n",
    "parser.add_argument('--cfg', dest='cfg_file', type=str, required=True,\n",
    "                    help='The configuration file path.')\n",
    "parser.add_argument('--repeat', type=int, default=1,\n",
    "                    help='The number of repeated jobs.')\n",
    "parser.add_argument('--mark_done', action='store_true',\n",
    "                    help='Mark yaml as done after a job has finished.')\n",
    "parser.add_argument('opts', default=None, nargs=argparse.REMAINDER,\n",
    "                    help='See graphgym/config.py for remaining options.')\n",
    "\n",
    "\n",
    "\n",
    "# Load cmd line args\n",
    "args = parser.parse_args(shlex.split('--cfg saved_results/yeast-LCQ-sageconv/config.yaml '\n",
    "                                     'dataset.remove_unlabeled_data False dataset.split [1,0,0]'))\n",
    "# args = parser.parse_args(shlex.split('--cfg /Users/cgu3/Documents/Grape-Pi/graphgym/configs/protein/gastric-graphsage.yaml'))\n",
    "# Load config file\n",
    "load_cfg(cfg, args)\n",
    "# Set Pytorch environment\n",
    "torch.set_num_threads(cfg.num_threads)\n",
    "# Repeat for different random seeds\n",
    "logger.set_printing()\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "auto_select_device()\n",
    "# Set machine learning pipeline\n",
    "\n",
    "model, datamodule = None, None\n",
    "# use the right customized datamodule and graphgymmodule\n",
    "if cfg.train.grape_pi == 'graphsage':\n",
    "    datamodule = train_dict['graphsage_graphgym_datamodule']()\n",
    "    model = train_dict['graphsage_create_model']()\n",
    "    # train = train_dict['graphsage_train']\n",
    "elif cfg.train.grape_pi == 'gcnconv':\n",
    "    datamodule = GraphGymDataModule()\n",
    "    model = train_dict['gcnconv_create_model']()\n",
    "    # train = train_dict['gcnconv_train']\n",
    "\n",
    "data_batch = next(iter(datamodule.loaders[0]))\n",
    "model(data_batch)\n",
    "\n",
    "# Print model info\n",
    "logging.info(model)\n",
    "logging.info(cfg)\n",
    "cfg.params = params_count(model)\n",
    "logging.info('Num parameters: %s', cfg.params)\n",
    "\n",
    "model.load_state_dict(torch.load('saved_results/yeast-LCQ-sageconv/epoch=299-step=4800.ckpt')['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6e1c6b318653d25e"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# get the dictionary mapping from global node index to original protein accession\n",
    "mapping = pd.read_csv('data/yeast-LCQ/yeast-LCQ_mapping.csv')\n",
    "# create dictionary mapping from global node index to original protein accession\n",
    "mapping = dict(zip(mapping['integer_id'], mapping['protein_id']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:02.419154Z",
     "start_time": "2024-05-27T18:32:02.413469Z"
    }
   },
   "id": "19e2f1e17750bb8d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "354a3eb7d77f05d"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "GraphsageGraphGymModule(\n  (model): GNN(\n    (encoder): FeatureEncoder()\n    (pre_mp): GeneralMultiLayer(\n      (Layer_0): GeneralLayer(\n        (layer): Linear(\n          (model): Linear(1, 10, bias=True)\n        )\n        (post_layer): Sequential(\n          (0): ReLU()\n        )\n      )\n    )\n    (mp): GNNStackStage(\n      (layer0): GeneralLayer(\n        (layer): SAGEConv(\n          (model): SAGEConv(10, 10, aggr=mean)\n        )\n        (post_layer): Sequential(\n          (0): ReLU()\n        )\n      )\n    )\n    (post_mp): ExampleNodeHead(\n      (layer_post_mp): MLP(\n        (model): Sequential(\n          (0): Linear(\n            (model): Linear(10, 1, bias=True)\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check why it is full-size batch and need to have original ID in the dataset\n",
    "# how to retrieve original ID\n",
    "model.eval()\n",
    "accession_indices = []\n",
    "all_pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in datamodule.loaders[0]:\n",
    "        # batch = batch.to(cfg.accelerator)\n",
    "        \n",
    "        # for each batch, only use test nodes in the original mini-batch nodes\n",
    "        # batch_mask = torch.cat([torch.ones(batch.batch_size), torch.zeros(len(batch.y) - batch.batch_size)], dim=0)\n",
    "        # batch_mask = batch_mask.bool()\n",
    "        # # mask = batch_mask & batch.test_mask\n",
    "        # # raw_prob = batch.x[:, 0][mask]\n",
    "        # raw_prob = batch.x[:, 0][batch_mask]\n",
    "        \n",
    "        logits, true = model(batch)\n",
    "\n",
    "        # for each batch, only use test nodes in the original mini-batch nodes\n",
    "        # global_node_idx = batch.n_id[mask]\n",
    "        # original_id = [mapping[key] for key in global_node_idx.tolist()]\n",
    "        \n",
    "        logits, true, index = logits[:batch.batch_size], true[:batch.batch_size], batch.n_id[:batch.batch_size]\n",
    "        logits = logits.squeeze(-1)\n",
    "        pred_prob = torch.nn.functional.sigmoid(logits)\n",
    "        \n",
    "        accession_indices += index.tolist()\n",
    "        all_pred_prob += pred_prob.tolist()\n",
    "        # print(original_id)\n",
    "        # print(pred_prob)\n",
    "        # print(true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:02.458330Z",
     "start_time": "2024-05-27T18:32:02.419670Z"
    }
   },
   "id": "986b5921dd2bb4b5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# convert the global node index to original protein accession\n",
    "accession = [mapping[key] for key in accession_indices]\n",
    "\n",
    "all_proteins_df = pd.DataFrame({'accession': accession, 'pred_prob': all_pred_prob})\n",
    "\n",
    "dat = pd.read_csv('data/yeast-LCQ/raw/protein/yeast-LCQ.csv')\n",
    "# combine the test_proteins_df with the original protein data\n",
    "all_proteins_df = all_proteins_df .merge(dat, left_on='accession', right_on='protein', how='inner')\n",
    "all_proteins_df.to_csv('/Users/cgu3/Documents/Grape-Pi/notebooks/post-training-evaluation/results'\n",
    "                       '/yeast_LCQ_all_proteins_df'\n",
    "                       '.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:02.471676Z",
     "start_time": "2024-05-27T18:32:02.459602Z"
    }
   },
   "id": "9c0c316b6ee80e8a",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:02.473461Z",
     "start_time": "2024-05-27T18:32:02.472304Z"
    }
   },
   "id": "f2e2aaeb14a86d8d",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For yeast-ORBI dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b50b3b73ef264ed"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--cfg'], dest='cfg_file', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, required=True, help='The configuration file path.', metavar=None)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=['--repeat'], dest='repeat', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, required=False, help='The number of repeated jobs.', metavar=None)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "_StoreTrueAction(option_strings=['--mark_done'], dest='mark_done', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Mark yaml as done after a job has finished.', metavar=None)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "_StoreAction(option_strings=[], dest='opts', nargs='...', const=None, default=None, type=None, choices=None, required=True, help='See graphgym/config.py for remaining options.', metavar=None)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[-0.0982],\n         [-0.0943],\n         [-0.1238],\n         ...,\n         [-0.0374],\n         [-0.0533],\n         [-0.0533]], grad_fn=<AddmmBackward0>),\n tensor([0, 0, 1,  ..., 0, 1, 1], dtype=torch.int32))"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphsageGraphGymModule(\n",
      "  (model): GNN(\n",
      "    (encoder): FeatureEncoder()\n",
      "    (pre_mp): GeneralMultiLayer(\n",
      "      (Layer_0): GeneralLayer(\n",
      "        (layer): Linear(\n",
      "          (model): Linear(1, 10, bias=True)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mp): GNNStackStage(\n",
      "      (layer0): GeneralLayer(\n",
      "        (layer): SAGEConv(\n",
      "          (model): SAGEConv(10, 10, aggr=mean)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_mp): ExampleNodeHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): Linear(\n",
      "            (model): Linear(10, 1, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cpu\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: data/yeast-ORBI\n",
      "  edge_dim: 128\n",
      "  edge_encoder: False\n",
      "  edge_encoder_bn: True\n",
      "  edge_encoder_name: Bond\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: False\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: PyG\n",
      "  label_column: None\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: protein\n",
      "  node_encoder: False\n",
      "  node_encoder_bn: True\n",
      "  node_encoder_name: Atom\n",
      "  numeric_columns: ['protein_probability']\n",
      "  rebuild: True\n",
      "  remove_feature: False\n",
      "  remove_unlabeled_data: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  split: [1, 0, 0]\n",
      "  split_mode: random\n",
      "  task: node\n",
      "  task_type: classification\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "devices: None\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: add\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: False\n",
      "  clear_feature: True\n",
      "  dim_inner: 10\n",
      "  dropout: 0.0\n",
      "  head: protein\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: sageconv\n",
      "  layers_mp: 1\n",
      "  layers_post_mp: 1\n",
      "  layers_pre_mp: 1\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: skipsum\n",
      "gpu_mem: False\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: auc\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: add\n",
      "  loss_fun: binary_cross_entropy_with_weight\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: gnn\n",
      "num_threads: 6\n",
      "num_workers: 8\n",
      "optim:\n",
      "  base_lr: 0.001\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 300\n",
      "  momentum: 0.9\n",
      "  optimizer: adam\n",
      "  scheduler: none\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 0.0005\n",
      "out_dir: results/yeast-graphsage\n",
      "params: 241\n",
      "print: both\n",
      "round: 4\n",
      "run_dir: results/yeast-graphsage\n",
      "seed: 1234\n",
      "share:\n",
      "  dim_in: 1\n",
      "  dim_out: 2\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: False\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 128\n",
      "  ckpt_clean: False\n",
      "  ckpt_period: 10\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: 0\n",
      "  eval_period: 10\n",
      "  grape_pi: graphsage\n",
      "  iter_per_epoch: 32\n",
      "  loss_pos_weight: 1.2393579902302863\n",
      "  neighbor_sizes: [20, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: neighbor\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "Num parameters: 241\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import custom_graphgym # noqa, register custom modules\n",
    "import torch\n",
    "from torch_geometric import seed_everything\n",
    "import argparse\n",
    "from torch_geometric.graphgym.config import (\n",
    "    cfg,\n",
    "    dump_cfg,\n",
    "    load_cfg,\n",
    "    set_out_dir,\n",
    "    set_run_dir,\n",
    ")\n",
    "from torch_geometric.graphgym.model_builder import create_model\n",
    "from torch_geometric.graphgym.register import train_dict\n",
    "from torch_geometric.graphgym.train import GraphGymDataModule, train\n",
    "from torch_geometric.graphgym.utils.agg_runs import agg_runs\n",
    "from torch_geometric.graphgym.utils.comp_budget import params_count\n",
    "from torch_geometric.graphgym.utils.device import auto_select_device\n",
    "\n",
    "from graphgym import logger\n",
    "import shlex\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GraphGym')\n",
    "parser.add_argument('--cfg', dest='cfg_file', type=str, required=True,\n",
    "                    help='The configuration file path.')\n",
    "parser.add_argument('--repeat', type=int, default=1,\n",
    "                    help='The number of repeated jobs.')\n",
    "parser.add_argument('--mark_done', action='store_true',\n",
    "                    help='Mark yaml as done after a job has finished.')\n",
    "parser.add_argument('opts', default=None, nargs=argparse.REMAINDER,\n",
    "                    help='See graphgym/config.py for remaining options.')\n",
    "\n",
    "\n",
    "\n",
    "# Load cmd line args\n",
    "args = parser.parse_args(shlex.split('--cfg saved_results/yeast-ORBI-sageconv/config.yaml '\n",
    "                                     'dataset.remove_unlabeled_data False dataset.split [1,0,0]'))\n",
    "# args = parser.parse_args(shlex.split('--cfg /Users/cgu3/Documents/Grape-Pi/graphgym/configs/protein/gastric-graphsage.yaml'))\n",
    "# Load config file\n",
    "load_cfg(cfg, args)\n",
    "# Set Pytorch environment\n",
    "torch.set_num_threads(cfg.num_threads)\n",
    "# Repeat for different random seeds\n",
    "logger.set_printing()\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "auto_select_device()\n",
    "# Set machine learning pipeline\n",
    "\n",
    "model, datamodule = None, None\n",
    "# use the right customized datamodule and graphgymmodule\n",
    "if cfg.train.grape_pi == 'graphsage':\n",
    "    datamodule = train_dict['graphsage_graphgym_datamodule']()\n",
    "    model = train_dict['graphsage_create_model']()\n",
    "    # train = train_dict['graphsage_train']\n",
    "elif cfg.train.grape_pi == 'gcnconv':\n",
    "    datamodule = GraphGymDataModule()\n",
    "    model = train_dict['gcnconv_create_model']()\n",
    "    # train = train_dict['gcnconv_train']\n",
    "\n",
    "data_batch = next(iter(datamodule.loaders[0]))\n",
    "model(data_batch)\n",
    "\n",
    "# Print model info\n",
    "logging.info(model)\n",
    "logging.info(cfg)\n",
    "cfg.params = params_count(model)\n",
    "logging.info('Num parameters: %s', cfg.params)\n",
    "\n",
    "model.load_state_dict(torch.load('saved_results/yeast-ORBI-sageconv/epoch=299-step=4800.ckpt')['state_dict'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:06.219969Z",
     "start_time": "2024-05-27T18:32:02.473856Z"
    }
   },
   "id": "64dae37372f92b72",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get the dictionary mapping from global node index to original protein accession\n",
    "mapping = pd.read_csv('data/yeast-ORBI/yeast-ORBI_mapping.csv')\n",
    "# create dictionary mapping from global node index to original protein accession\n",
    "mapping = dict(zip(mapping['integer_id'], mapping['protein_id']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:06.225774Z",
     "start_time": "2024-05-27T18:32:06.220748Z"
    }
   },
   "id": "39d26f804e869c58",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GraphsageGraphGymModule(\n  (model): GNN(\n    (encoder): FeatureEncoder()\n    (pre_mp): GeneralMultiLayer(\n      (Layer_0): GeneralLayer(\n        (layer): Linear(\n          (model): Linear(1, 10, bias=True)\n        )\n        (post_layer): Sequential(\n          (0): ReLU()\n        )\n      )\n    )\n    (mp): GNNStackStage(\n      (layer0): GeneralLayer(\n        (layer): SAGEConv(\n          (model): SAGEConv(10, 10, aggr=mean)\n        )\n        (post_layer): Sequential(\n          (0): ReLU()\n        )\n      )\n    )\n    (post_mp): ExampleNodeHead(\n      (layer_post_mp): MLP(\n        (model): Sequential(\n          (0): Linear(\n            (model): Linear(10, 1, bias=True)\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check why it is full-size batch and need to have original ID in the dataset\n",
    "# how to retrieve original ID\n",
    "model.eval()\n",
    "accession_indices = []\n",
    "all_pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in datamodule.loaders[0]:\n",
    "        # batch = batch.to(cfg.accelerator)\n",
    "\n",
    "        # for each batch, only use test nodes in the original mini-batch nodes\n",
    "        # batch_mask = torch.cat([torch.ones(batch.batch_size), torch.zeros(len(batch.y) - batch.batch_size)], dim=0)\n",
    "        # batch_mask = batch_mask.bool()\n",
    "        # # mask = batch_mask & batch.test_mask\n",
    "        # # raw_prob = batch.x[:, 0][mask]\n",
    "        # raw_prob = batch.x[:, 0][batch_mask]\n",
    "\n",
    "        logits, true = model(batch)\n",
    "\n",
    "        # for each batch, only use test nodes in the original mini-batch nodes\n",
    "        # global_node_idx = batch.n_id[mask]\n",
    "        # original_id = [mapping[key] for key in global_node_idx.tolist()]\n",
    "\n",
    "        logits, true, index = logits[:batch.batch_size], true[:batch.batch_size], batch.n_id[:batch.batch_size]\n",
    "        logits = logits.squeeze(-1)\n",
    "        pred_prob = torch.nn.functional.sigmoid(logits)\n",
    "\n",
    "        accession_indices += index.tolist()\n",
    "        all_pred_prob += pred_prob.tolist()\n",
    "        # print(original_id)\n",
    "        # print(pred_prob)\n",
    "        # print(true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:06.261960Z",
     "start_time": "2024-05-27T18:32:06.226367Z"
    }
   },
   "id": "c81f3bc7d6f78d86",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# convert the global node index to original protein accession\n",
    "accession = [mapping[key] for key in accession_indices]\n",
    "\n",
    "all_proteins_df = pd.DataFrame({'accession': accession, 'pred_prob': all_pred_prob})\n",
    "\n",
    "dat = pd.read_csv('data/yeast-ORBI/raw/protein/yeast-ORBI.csv')\n",
    "# combine the test_proteins_df with the original protein data\n",
    "all_proteins_df = all_proteins_df .merge(dat, left_on='accession', right_on='protein', how='inner')\n",
    "all_proteins_df.to_csv('/Users/cgu3/Documents/Grape-Pi/notebooks/post-training-evaluation/results'\n",
    "                       '/yeast_ORBI_all_proteins_df'\n",
    "                       '.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:06.274747Z",
     "start_time": "2024-05-27T18:32:06.262613Z"
    }
   },
   "id": "aa1ff602891d0ba3",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:06.277523Z",
     "start_time": "2024-05-27T18:32:06.276401Z"
    }
   },
   "id": "82599fe4f09e8aad",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:32:06.278933Z",
     "start_time": "2024-05-27T18:32:06.277951Z"
    }
   },
   "id": "91e16a6acc891ddd",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e4f50c9030c1315e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
